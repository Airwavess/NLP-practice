{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.load_userdict(\"./dict.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def cal_dist(self, p0, p1):\n",
    "        \"\"\"\n",
    "        比較兩點的距離\n",
    "        \"\"\"\n",
    "        return dot(p0, p1)/(norm(p0)*norm(p1))\n",
    "\n",
    "    def kmeans(self, datapoints, k=2):\n",
    "        # 定義資料維度\n",
    "        d = datapoints.shape[1]\n",
    "        # 最大的迭代次數\n",
    "        Max_Iterations = 1000\n",
    "\n",
    "        cluster = np.zeros(datapoints.shape[0])\n",
    "        prev_cluster = np.ones(datapoints.shape[0])\n",
    "\n",
    "        cluster_centers = []\n",
    "        for i in range(k):\n",
    "            cluster_centers += [random.choice(datapoints)]\n",
    "\n",
    "        iteration = 0\n",
    "        while np.array_equal(cluster, prev_cluster) is False or iteration > Max_Iterations:\n",
    "            iteration += 1\n",
    "            prev_cluster = cluster.copy()\n",
    "\n",
    "            # 將每一個點做分群\n",
    "            for idx, point in enumerate(datapoints):\n",
    "                min_dist = float(\"inf\")\n",
    "                for c, cluster_center in enumerate(cluster_centers):\n",
    "                    dist = self.cal_dist(point, cluster_center)\n",
    "                    if dist == 'nan':\n",
    "                        print(point)\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist  \n",
    "                        cluster[idx] = c   # 指定該點屬於哪個分群\n",
    "\n",
    "            # 更新分群的中心\n",
    "            for k in range(len(cluster_centers)):\n",
    "                new_center = np.zeros(d)\n",
    "                members = 0\n",
    "                for point, c in zip(datapoints, cluster):\n",
    "                    if c == k:\n",
    "                        new_center += point\n",
    "                        members += 1\n",
    "                if members > 0:\n",
    "                    new_center = new_center / members\n",
    "                cluster_centers[k] = new_center\n",
    "\n",
    "        return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料\n",
    "DATASET_DIR = './speech.json'\n",
    "with open(DATASET_DIR) as f:\n",
    "    dataset = json.load(f)\n",
    "    \n",
    "# 讀取 stop words\n",
    "STOP_WORDS_DIR = './stop_words.txt'\n",
    "with open(STOP_WORDS_DIR) as f:\n",
    "    stop_words = f.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取演講內容與縣市\n",
    "speech_list = list(map(lambda d: d['speech'], dataset))\n",
    "country_list = list(map(lambda d: d['country'], dataset))\n",
    "\n",
    "# 去除繁體中文以外的英文、數字、符號\n",
    "rule = re.compile(r\"[^\\u4e00-\\u9fa5]\")\n",
    "speech_list = [list(jieba.cut(rule.sub('', speech))) for speech in speech_list]\n",
    "for idx, speech in enumerate(speech_list):\n",
    "    speech_list[idx] = ' '.join([word for word in speech if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(speech_list)\n",
    "tfidf = tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-9f1c7e56ddbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mKmeans_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mspeech_cluster_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKmeans_cluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-469e125eda01>\u001b[0m in \u001b[0;36mkmeans\u001b[0;34m(self, datapoints, k)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mmin_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_center\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_centers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcal_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_center\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nan'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-469e125eda01>\u001b[0m in \u001b[0;36mcal_dist\u001b[0;34m(self, p0, p1)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0m比較兩點的距離\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatapoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "Kmeans_cluster = KMeans()\n",
    "speech_cluster_result = Kmeans_cluster.kmeans(tfidf, k)\n",
    "cluster = [[] for _ in range(k)]\n",
    "\n",
    "for idx, c in enumerate(speech_cluster_result):\n",
    "    cluster[int(c)].append(country_list[idx])\n",
    "    \n",
    "for c, result in enumerate(cluster):\n",
    "    print('Cluster {}: {}'.format(c, ' '.join(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
