{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.load_userdict(\"./dict.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def cal_dist(self, p0, p1):\n",
    "        \"\"\"\n",
    "        比較兩點的距離\n",
    "        \"\"\"\n",
    "#         return cosine_similarity([p0], [p1])[0][0]\n",
    "        return np.sqrt(np.sum((p0-p1)**2))\n",
    "    \n",
    "    def nearest_cluster_center(self, point, cluster_centers):\n",
    "        \"\"\"\n",
    "        找到距離 point 最近的中心點\n",
    "        \"\"\"\n",
    "        min_dist = float(\"inf\")\n",
    "        m = cluster_centers.shape[0]\n",
    "        for i in range(m):\n",
    "            d = self.cal_dist(point, cluster_centers[i])\n",
    "            if min_dist > d:\n",
    "                min_dist = d\n",
    "        return min_dist \n",
    "\n",
    "    def get_centroids(self, datapoints, k):\n",
    "        \"\"\"\n",
    "        K-means++ 演算法，取得初始化中心點\n",
    "        \"\"\"\n",
    "        clusters = np.array([random.choice(datapoints)])\n",
    "        dist = np.zeros(len(datapoints))\n",
    "        \n",
    "        for i in range(k-1):\n",
    "            sum_dist = 0\n",
    "            for j, point in enumerate(datapoints):\n",
    "                dist[j] = self.nearest_cluster_center(point, clusters)\n",
    "                sum_dist += dist[j]\n",
    "            \n",
    "            sum_dist *= random.random()\n",
    "            for j, d in enumerate(dist):\n",
    "                sum_dist = sum_dist - d\n",
    "                if sum_dist <= 0:\n",
    "                    clusters = np.append(clusters, [datapoints[j]], axis=0)\n",
    "                    break\n",
    "        \n",
    "        return clusters\n",
    "        \n",
    "        \n",
    "    def kmeans_plus_plus(self, datapoints, k=2):\n",
    "        \"\"\"\n",
    "        K-means 演算法\n",
    "        \"\"\"\n",
    "        # 定義資料維度\n",
    "        d = datapoints.shape[1]\n",
    "        # 最大的迭代次數\n",
    "        Max_Iterations = 1000\n",
    "\n",
    "        cluster = np.zeros(datapoints.shape[0])\n",
    "        prev_cluster = np.ones(datapoints.shape[0])\n",
    "\n",
    "        cluster_centers = self.get_centroids(datapoints, k)\n",
    "\n",
    "        iteration = 0\n",
    "        while np.array_equal(cluster, prev_cluster) is False or iteration > Max_Iterations:\n",
    "            iteration += 1\n",
    "            prev_cluster = cluster.copy()\n",
    "\n",
    "            # 將每一個點做分群\n",
    "            for idx, point in enumerate(datapoints):\n",
    "                min_dist = float(\"inf\")\n",
    "                for c, cluster_center in enumerate(cluster_centers):\n",
    "                    dist = self.cal_dist(point, cluster_center)\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist  \n",
    "                        cluster[idx] = c   # 指定該點屬於哪個分群\n",
    "\n",
    "            # 更新分群的中心\n",
    "            for k in range(len(cluster_centers)):\n",
    "                new_center = np.zeros(d)\n",
    "                members = 0\n",
    "                for point, c in zip(datapoints, cluster):\n",
    "                    if c == k:\n",
    "                        new_center += point\n",
    "                        members += 1\n",
    "                if members > 0:\n",
    "                    new_center = new_center / members\n",
    "                cluster_centers[k] = new_center\n",
    "\n",
    "        return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料\n",
    "DATASET_DIR = './speech.json'\n",
    "with open(DATASET_DIR, encoding = 'utf8') as f:\n",
    "    dataset = json.load(f)\n",
    "    \n",
    "# 讀取 stop words\n",
    "STOP_WORDS_DIR = './stop_words.txt'\n",
    "with open(STOP_WORDS_DIR, encoding = 'utf8') as f:\n",
    "    stop_words = f.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取演講內容與縣市\n",
    "speech_list = list(map(lambda d: d['speech'], dataset))\n",
    "country_list = list(map(lambda d: d['country'], dataset))\n",
    "\n",
    "# 去除繁體中文以外的英文、數字、符號\n",
    "rule = re.compile(r\"[^\\u4e00-\\u9fa5]\")\n",
    "speech_list = [list(jieba.cut(rule.sub('', speech))) for speech in speech_list]\n",
    "for idx, speech in enumerate(speech_list):\n",
    "    speech_list[idx] = ' '.join([word for word in speech if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(speech_list)\n",
    "tfidf = tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 新北市 桃園市 臺中市 台南市 高雄市 新竹市 嘉義市\n",
      "Cluster 1: 彰化縣 南投縣 雲林縣 嘉義縣\n",
      "Cluster 2: 台北市\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "Kmeans_cluster = KMeans()\n",
    "speech_cluster_result = Kmeans_cluster.kmeans_plus_plus(tfidf, k)\n",
    "cluster = [[] for _ in range(k)]\n",
    "\n",
    "for idx, c in enumerate(speech_cluster_result):\n",
    "    cluster[int(c)].append(country_list[idx])\n",
    "    \n",
    "for c, result in enumerate(cluster):\n",
    "    print('Cluster {}: {}'.format(c, ' '.join(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
